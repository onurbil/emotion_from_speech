{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bayesian Optimization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6NYTcAvln4J"
      },
      "source": [
        "### Mount Google Drive\n",
        "\n",
        "**Requires dataset_tensor.npy file in \"Colab Notebooks/Tensorized Transformers/Data\" folder!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XNfw-0EfZ4B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42d4e3c8-c82c-4c59-b4d5-66c4825c3ebe"
      },
      "source": [
        "! pip install -q pyyaml h5py  # Required to save models in HDF5 format\r\n",
        "! pip install torch\r\n",
        "! pip install tqdm\r\n",
        "! pip install torchsummary\r\n",
        "! pip install bayesian-optimization\r\n",
        "\r\n",
        "import torch\r\n",
        "from torchsummary import summary\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.7.1+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.41.1)\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.7/dist-packages (1.5.1)\n",
            "Collecting bayesian-optimization\n",
            "  Downloading https://files.pythonhosted.org/packages/bb/7a/fd8059a3881d3ab37ac8f72f56b73937a14e8bb14a9733e68cc8b17dbe3c/bayesian-optimization-1.2.0.tar.gz\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (1.0.1)\n",
            "Building wheels for collected packages: bayesian-optimization\n",
            "  Building wheel for bayesian-optimization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bayesian-optimization: filename=bayesian_optimization-1.2.0-cp37-none-any.whl size=11687 sha256=bed08b8b73477d96b74e7b84e975b50b756c0ab31fbf46870059a89a0a57d64d\n",
            "  Stored in directory: /root/.cache/pip/wheels/5a/56/ae/e0e3c1fc1954dc3ec712e2df547235ed072b448094d8f94aec\n",
            "Successfully built bayesian-optimization\n",
            "Installing collected packages: bayesian-optimization\n",
            "Successfully installed bayesian-optimization-1.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaNZqkhqfjiJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5388b666-4ec0-4fdd-8e78-21ded305175c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "PATH = '/content/drive/My Drive/Colab Notebooks/Emotion from Speech/'\n",
        "DATA_PATH = PATH + 'Data/'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHxUZWqils8I"
      },
      "source": [
        "### Clone Tensorized Transformers and multidim conv github repository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmKol2g8WU1d"
      },
      "source": [
        "git_username = ''\n",
        "git_token =  ''\n",
        "\n",
        "if git_username == '':\n",
        "  print('Github username:')\n",
        "  git_username = %sx read -p ''\n",
        "  git_username = git_username[0]\n",
        "\n",
        "if git_token == '':\n",
        "  print('Github access token (https://github.com/settings/tokens):')\n",
        "  print('Github Token:')\n",
        "  git_token = %sx read -p ''\n",
        "  git_token = git_token[0]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KA6Ej0xOjzbu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9286bc66-1b0e-4a5a-ae80-9191346ef636"
      },
      "source": [
        "# Clone the entire repo.\n",
        "%cd /content\n",
        "!git clone -l -s https://$git_username:$git_token@github.com/onurbil/emotion_from_speech.git emotion_from_speech\n",
        "%cd emotion_from_speech\n",
        "!ls\n",
        "%cd .."
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'emotion_from_speech'...\n",
            "warning: --local is ignored\n",
            "remote: Enumerating objects: 91, done.\u001b[K\n",
            "remote: Counting objects: 100% (91/91), done.\u001b[K\n",
            "remote: Compressing objects: 100% (64/64), done.\u001b[K\n",
            "remote: Total 91 (delta 45), reused 64 (delta 21), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (91/91), done.\n",
            "/content/emotion_from_speech\n",
            "dataset.py  download.py  main.py  paths.py  README.md  rnn.py  training.py\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmfy2j6FkjLo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3981dc7-026f-4117-d4ba-7ad570782b5a"
      },
      "source": [
        "import sys\n",
        "\n",
        "REPO_PATH = '/content/emotion_from_speech'\n",
        "\n",
        "sys.path.append(REPO_PATH)\n",
        "print(sys.path)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['', '/content', '/env/python', '/usr/lib/python37.zip', '/usr/lib/python3.7', '/usr/lib/python3.7/lib-dynload', '/usr/local/lib/python3.7/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.7/dist-packages/IPython/extensions', '/root/.ipython', '/content/emotion_from_speech']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NTfnysd6TDj"
      },
      "source": [
        "\r\n",
        "---\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "# Experiments\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCbok4hOM1tP"
      },
      "source": [
        "## Tensorized Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRyMOq1gUepb",
        "outputId": "1d2cebac-ad56-4259-95ce-1c672ac4b55f"
      },
      "source": [
        "import torch \r\n",
        "\r\n",
        "if torch.cuda.is_available():\r\n",
        "    device = torch.cuda.current_device()\r\n",
        "    print('Current device:', torch.cuda.get_device_name(device))\r\n",
        "else:\r\n",
        "    print('Failed to find GPU. Will use CPU.')\r\n",
        "    device = 'cpu'"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Current device: Tesla K80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_yrY-hPiasS"
      },
      "source": [
        "import os\r\n",
        "from training import test_hyper_parameters\r\n",
        "import torch.nn.functional as F\r\n",
        "\r\n",
        "\r\n",
        "class Model(torch.nn.Module):\r\n",
        "    def __init__(self, num_layers, feature_num, hidden_size, linear_size, classes):\r\n",
        "        super(Model, self).__init__()\r\n",
        "\r\n",
        "        self.lstm = torch.nn.LSTM(num_layers=num_layers, input_size=feature_num, hidden_size=hidden_size,\r\n",
        "                                  batch_first=True)\r\n",
        "        self.fc1 = torch.nn.Linear(hidden_size, linear_size)\r\n",
        "        self.fc2 = torch.nn.Linear(linear_size, classes)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        x, hid = self.lstm(x)\r\n",
        "\r\n",
        "        x, _ = torch.nn.utils.rnn.pad_packed_sequence(x, batch_first=True)\r\n",
        "        x = x[:, -1, :]\r\n",
        "\r\n",
        "        x = self.fc1(x)\r\n",
        "        x = F.relu(x)\r\n",
        "        x = self.fc2(x)\r\n",
        "        x = F.relu(x)\r\n",
        "        x = F.log_softmax(x, dim=1)\r\n",
        "\r\n",
        "        return x\r\n",
        "\r\n",
        "\r\n",
        "def bayesian_optimization_function(dataset_path, device, num_runs, batch_size, num_epochs, lr_power, weight_decay, num_layers, hidden_size, linear_size, verbose=1):\r\n",
        "    batch_size = int(batch_size)\r\n",
        "    num_epochs = int(num_epochs)\r\n",
        "    learning_rate = 10**lr_power\r\n",
        "    weight_decay = max(weight_decay, 0)\r\n",
        "    model_args = {\r\n",
        "        'num_layers': int(num_layers),\r\n",
        "        'hidden_size': int(hidden_size),\r\n",
        "        'linear_size': int(linear_size),\r\n",
        "    }\r\n",
        "\r\n",
        "    mean_accuracy = test_hyper_parameters(num_runs=num_runs, dataset_path=dataset_path, batch_size=batch_size,\r\n",
        "                                          num_epochs=num_epochs, learning_rate=learning_rate, weight_decay=weight_decay,\r\n",
        "                                          model_cls=Model, model_args=model_args, device=device, verbose=verbose)\r\n",
        "    if verbose >= 1:\r\n",
        "      print(f'\\nMean accuracy: {mean_accuracy*100:.4f}%')\r\n",
        "    return mean_accuracy"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oPITkYFwkNfi",
        "outputId": "6852adc2-f636-4d9a-f77e-0afb5fd37bd5"
      },
      "source": [
        "from functools import partial\r\n",
        "import time\r\n",
        "from bayes_opt import BayesianOptimization\r\n",
        "\r\n",
        "dataset_path = os.path.join(DATA_PATH, 'data_list.npy')\r\n",
        "\r\n",
        "\r\n",
        "fn = partial(bayesian_optimization_function, \r\n",
        "             dataset_path=dataset_path, device=device, \r\n",
        "             num_runs=1, num_epochs=20, \r\n",
        "             verbose=0)\r\n",
        "\r\n",
        "pbounds = {\r\n",
        "    'batch_size': (2, 512), \r\n",
        "    'lr_power': (-10, -1),\r\n",
        "    'weight_decay': (0, .05),\r\n",
        "    'num_layers': (.51, 6.49),\r\n",
        "    'hidden_size': (8, 1024),\r\n",
        "    'linear_size': (8, 1024),\r\n",
        "    }\r\n",
        "\r\n",
        "optimizer = BayesianOptimization(\r\n",
        "    f=fn,\r\n",
        "    pbounds=pbounds,\r\n",
        "    random_state=1337,\r\n",
        ")\r\n",
        "\r\n",
        "\r\n",
        "start_time = time.time()\r\n",
        "\r\n",
        "optimizer.maximize(\r\n",
        "    init_points=50,\r\n",
        "    n_iter=30,\r\n",
        ")\r\n",
        "\r\n",
        "end_time = time.time()\r\n",
        "\r\n",
        "\r\n",
        "print(f'Optimization finished in {end_time-start_time:.1f} s')\r\n",
        "print(optimizer.max)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "|   iter    |  target   | batch_... | hidden... | linear... | lr_power  | num_la... | weight... |\n",
            "-------------------------------------------------------------------------------------------------\n",
            "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.14    \u001b[0m | \u001b[0m 135.6   \u001b[0m | \u001b[0m 169.2   \u001b[0m | \u001b[0m 290.6   \u001b[0m | \u001b[0m-5.866   \u001b[0m | \u001b[0m 2.43    \u001b[0m | \u001b[0m 0.02592 \u001b[0m |\n",
            "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.1217  \u001b[0m | \u001b[0m 135.6   \u001b[0m | \u001b[0m 999.7   \u001b[0m | \u001b[0m 752.5   \u001b[0m | \u001b[0m-8.963   \u001b[0m | \u001b[0m 2.82    \u001b[0m | \u001b[0m 0.03143 \u001b[0m |\n",
            "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.1217  \u001b[0m | \u001b[0m 65.78   \u001b[0m | \u001b[0m 1.007e+0\u001b[0m | \u001b[0m 458.3   \u001b[0m | \u001b[0m-2.894   \u001b[0m | \u001b[0m 5.259   \u001b[0m | \u001b[0m 0.01806 \u001b[0m |\n",
            "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.1383  \u001b[0m | \u001b[0m 214.2   \u001b[0m | \u001b[0m 601.6   \u001b[0m | \u001b[0m 780.3   \u001b[0m | \u001b[0m-8.31    \u001b[0m | \u001b[0m 2.233   \u001b[0m | \u001b[0m 0.03351 \u001b[0m |\n",
            "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.1217  \u001b[0m | \u001b[0m 256.8   \u001b[0m | \u001b[0m 189.4   \u001b[0m | \u001b[0m 427.8   \u001b[0m | \u001b[0m-8.207   \u001b[0m | \u001b[0m 3.69    \u001b[0m | \u001b[0m 0.04162 \u001b[0m |\n",
            "| \u001b[95m 6       \u001b[0m | \u001b[95m 0.2167  \u001b[0m | \u001b[95m 96.48   \u001b[0m | \u001b[95m 980.7   \u001b[0m | \u001b[95m 440.2   \u001b[0m | \u001b[95m-5.464   \u001b[0m | \u001b[95m 3.563   \u001b[0m | \u001b[95m 0.000789\u001b[0m |\n",
            "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.1467  \u001b[0m | \u001b[0m 375.2   \u001b[0m | \u001b[0m 1.017e+0\u001b[0m | \u001b[0m 173.5   \u001b[0m | \u001b[0m-8.86    \u001b[0m | \u001b[0m 2.752   \u001b[0m | \u001b[0m 0.03466 \u001b[0m |\n",
            "| \u001b[95m 8       \u001b[0m | \u001b[95m 0.235   \u001b[0m | \u001b[95m 3.48    \u001b[0m | \u001b[95m 383.1   \u001b[0m | \u001b[95m 67.62   \u001b[0m | \u001b[95m-2.896   \u001b[0m | \u001b[95m 2.602   \u001b[0m | \u001b[95m 0.03513 \u001b[0m |\n",
            "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.1433  \u001b[0m | \u001b[0m 252.5   \u001b[0m | \u001b[0m 996.4   \u001b[0m | \u001b[0m 857.3   \u001b[0m | \u001b[0m-4.508   \u001b[0m | \u001b[0m 3.886   \u001b[0m | \u001b[0m 0.04987 \u001b[0m |\n",
            "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.1433  \u001b[0m | \u001b[0m 131.9   \u001b[0m | \u001b[0m 22.61   \u001b[0m | \u001b[0m 98.47   \u001b[0m | \u001b[0m-1.549   \u001b[0m | \u001b[0m 6.331   \u001b[0m | \u001b[0m 0.02457 \u001b[0m |\n",
            "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.135   \u001b[0m | \u001b[0m 175.9   \u001b[0m | \u001b[0m 742.4   \u001b[0m | \u001b[0m 19.07   \u001b[0m | \u001b[0m-3.16    \u001b[0m | \u001b[0m 4.525   \u001b[0m | \u001b[0m 0.009522\u001b[0m |\n",
            "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.1217  \u001b[0m | \u001b[0m 341.9   \u001b[0m | \u001b[0m 933.7   \u001b[0m | \u001b[0m 172.7   \u001b[0m | \u001b[0m-1.805   \u001b[0m | \u001b[0m 2.45    \u001b[0m | \u001b[0m 0.03501 \u001b[0m |\n",
            "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.135   \u001b[0m | \u001b[0m 137.4   \u001b[0m | \u001b[0m 535.3   \u001b[0m | \u001b[0m 188.3   \u001b[0m | \u001b[0m-5.789   \u001b[0m | \u001b[0m 3.195   \u001b[0m | \u001b[0m 0.0198  \u001b[0m |\n",
            "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.1217  \u001b[0m | \u001b[0m 405.9   \u001b[0m | \u001b[0m 509.3   \u001b[0m | \u001b[0m 743.5   \u001b[0m | \u001b[0m-2.863   \u001b[0m | \u001b[0m 2.612   \u001b[0m | \u001b[0m 0.04548 \u001b[0m |\n",
            "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.1533  \u001b[0m | \u001b[0m 365.6   \u001b[0m | \u001b[0m 919.6   \u001b[0m | \u001b[0m 434.9   \u001b[0m | \u001b[0m-5.792   \u001b[0m | \u001b[0m 5.915   \u001b[0m | \u001b[0m 0.03168 \u001b[0m |\n",
            "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.1217  \u001b[0m | \u001b[0m 273.7   \u001b[0m | \u001b[0m 249.3   \u001b[0m | \u001b[0m 969.6   \u001b[0m | \u001b[0m-4.965   \u001b[0m | \u001b[0m 5.039   \u001b[0m | \u001b[0m 0.01181 \u001b[0m |\n",
            "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.105   \u001b[0m | \u001b[0m 221.2   \u001b[0m | \u001b[0m 408.4   \u001b[0m | \u001b[0m 526.9   \u001b[0m | \u001b[0m-8.871   \u001b[0m | \u001b[0m 4.598   \u001b[0m | \u001b[0m 0.001384\u001b[0m |\n",
            "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.185   \u001b[0m | \u001b[0m 121.3   \u001b[0m | \u001b[0m 756.2   \u001b[0m | \u001b[0m 957.2   \u001b[0m | \u001b[0m-4.478   \u001b[0m | \u001b[0m 2.947   \u001b[0m | \u001b[0m 0.0427  \u001b[0m |\n",
            "| \u001b[95m 19      \u001b[0m | \u001b[95m 0.2683  \u001b[0m | \u001b[95m 508.3   \u001b[0m | \u001b[95m 308.1   \u001b[0m | \u001b[95m 404.4   \u001b[0m | \u001b[95m-3.709   \u001b[0m | \u001b[95m 2.645   \u001b[0m | \u001b[95m 0.001596\u001b[0m |\n",
            "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.1433  \u001b[0m | \u001b[0m 180.1   \u001b[0m | \u001b[0m 500.5   \u001b[0m | \u001b[0m 57.01   \u001b[0m | \u001b[0m-1.765   \u001b[0m | \u001b[0m 4.849   \u001b[0m | \u001b[0m 0.03862 \u001b[0m |\n",
            "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.1533  \u001b[0m | \u001b[0m 51.19   \u001b[0m | \u001b[0m 45.83   \u001b[0m | \u001b[0m 272.0   \u001b[0m | \u001b[0m-8.87    \u001b[0m | \u001b[0m 1.934   \u001b[0m | \u001b[0m 0.03411 \u001b[0m |\n",
            "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.1433  \u001b[0m | \u001b[0m 247.4   \u001b[0m | \u001b[0m 959.5   \u001b[0m | \u001b[0m 598.7   \u001b[0m | \u001b[0m-8.325   \u001b[0m | \u001b[0m 1.628   \u001b[0m | \u001b[0m 0.01693 \u001b[0m |\n",
            "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.145   \u001b[0m | \u001b[0m 222.7   \u001b[0m | \u001b[0m 86.0    \u001b[0m | \u001b[0m 654.2   \u001b[0m | \u001b[0m-9.474   \u001b[0m | \u001b[0m 4.838   \u001b[0m | \u001b[0m 0.03301 \u001b[0m |\n",
            "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.2367  \u001b[0m | \u001b[0m 6.497   \u001b[0m | \u001b[0m 783.4   \u001b[0m | \u001b[0m 352.1   \u001b[0m | \u001b[0m-3.014   \u001b[0m | \u001b[0m 2.518   \u001b[0m | \u001b[0m 0.02903 \u001b[0m |\n",
            "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.1533  \u001b[0m | \u001b[0m 89.71   \u001b[0m | \u001b[0m 867.8   \u001b[0m | \u001b[0m 283.2   \u001b[0m | \u001b[0m-3.298   \u001b[0m | \u001b[0m 3.879   \u001b[0m | \u001b[0m 0.045   \u001b[0m |\n",
            "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.1433  \u001b[0m | \u001b[0m 281.6   \u001b[0m | \u001b[0m 33.54   \u001b[0m | \u001b[0m 89.93   \u001b[0m | \u001b[0m-1.4     \u001b[0m | \u001b[0m 3.237   \u001b[0m | \u001b[0m 0.007367\u001b[0m |\n",
            "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.145   \u001b[0m | \u001b[0m 346.2   \u001b[0m | \u001b[0m 641.6   \u001b[0m | \u001b[0m 567.0   \u001b[0m | \u001b[0m-1.848   \u001b[0m | \u001b[0m 5.882   \u001b[0m | \u001b[0m 0.01312 \u001b[0m |\n",
            "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.17    \u001b[0m | \u001b[0m 368.8   \u001b[0m | \u001b[0m 500.9   \u001b[0m | \u001b[0m 293.4   \u001b[0m | \u001b[0m-9.475   \u001b[0m | \u001b[0m 1.736   \u001b[0m | \u001b[0m 0.032   \u001b[0m |\n",
            "| \u001b[0m 29      \u001b[0m | \u001b[0m 0.1633  \u001b[0m | \u001b[0m 147.8   \u001b[0m | \u001b[0m 457.6   \u001b[0m | \u001b[0m 359.5   \u001b[0m | \u001b[0m-5.502   \u001b[0m | \u001b[0m 4.427   \u001b[0m | \u001b[0m 0.04747 \u001b[0m |\n",
            "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.1383  \u001b[0m | \u001b[0m 18.87   \u001b[0m | \u001b[0m 573.2   \u001b[0m | \u001b[0m 659.1   \u001b[0m | \u001b[0m-8.574   \u001b[0m | \u001b[0m 4.854   \u001b[0m | \u001b[0m 0.01893 \u001b[0m |\n",
            "| \u001b[95m 31      \u001b[0m | \u001b[95m 0.2767  \u001b[0m | \u001b[95m 262.9   \u001b[0m | \u001b[95m 595.5   \u001b[0m | \u001b[95m 866.8   \u001b[0m | \u001b[95m-3.684   \u001b[0m | \u001b[95m 4.273   \u001b[0m | \u001b[95m 0.002567\u001b[0m |\n",
            "| \u001b[95m 32      \u001b[0m | \u001b[95m 0.8067  \u001b[0m | \u001b[95m 25.41   \u001b[0m | \u001b[95m 545.5   \u001b[0m | \u001b[95m 803.6   \u001b[0m | \u001b[95m-3.672   \u001b[0m | \u001b[95m 1.686   \u001b[0m | \u001b[95m 0.01359 \u001b[0m |\n",
            "| \u001b[0m 33      \u001b[0m | \u001b[0m 0.1633  \u001b[0m | \u001b[0m 111.8   \u001b[0m | \u001b[0m 422.9   \u001b[0m | \u001b[0m 673.8   \u001b[0m | \u001b[0m-7.567   \u001b[0m | \u001b[0m 2.187   \u001b[0m | \u001b[0m 0.03909 \u001b[0m |\n",
            "| \u001b[0m 34      \u001b[0m | \u001b[0m 0.1533  \u001b[0m | \u001b[0m 436.6   \u001b[0m | \u001b[0m 564.2   \u001b[0m | \u001b[0m 743.7   \u001b[0m | \u001b[0m-6.101   \u001b[0m | \u001b[0m 5.417   \u001b[0m | \u001b[0m 0.04122 \u001b[0m |\n",
            "| \u001b[0m 35      \u001b[0m | \u001b[0m 0.1533  \u001b[0m | \u001b[0m 10.44   \u001b[0m | \u001b[0m 752.8   \u001b[0m | \u001b[0m 736.7   \u001b[0m | \u001b[0m-3.527   \u001b[0m | \u001b[0m 5.211   \u001b[0m | \u001b[0m 0.04686 \u001b[0m |\n",
            "| \u001b[0m 36      \u001b[0m | \u001b[0m 0.1433  \u001b[0m | \u001b[0m 337.7   \u001b[0m | \u001b[0m 198.5   \u001b[0m | \u001b[0m 707.2   \u001b[0m | \u001b[0m-1.086   \u001b[0m | \u001b[0m 5.978   \u001b[0m | \u001b[0m 0.04325 \u001b[0m |\n",
            "| \u001b[0m 37      \u001b[0m | \u001b[0m 0.1433  \u001b[0m | \u001b[0m 25.82   \u001b[0m | \u001b[0m 15.96   \u001b[0m | \u001b[0m 769.5   \u001b[0m | \u001b[0m-3.398   \u001b[0m | \u001b[0m 4.746   \u001b[0m | \u001b[0m 0.007854\u001b[0m |\n",
            "| \u001b[0m 38      \u001b[0m | \u001b[0m 0.1383  \u001b[0m | \u001b[0m 62.46   \u001b[0m | \u001b[0m 171.0   \u001b[0m | \u001b[0m 844.3   \u001b[0m | \u001b[0m-6.367   \u001b[0m | \u001b[0m 1.581   \u001b[0m | \u001b[0m 0.03157 \u001b[0m |\n",
            "| \u001b[0m 39      \u001b[0m | \u001b[0m 0.135   \u001b[0m | \u001b[0m 21.44   \u001b[0m | \u001b[0m 103.6   \u001b[0m | \u001b[0m 121.5   \u001b[0m | \u001b[0m-3.795   \u001b[0m | \u001b[0m 4.201   \u001b[0m | \u001b[0m 0.02869 \u001b[0m |\n",
            "| \u001b[0m 40      \u001b[0m | \u001b[0m 0.1533  \u001b[0m | \u001b[0m 423.3   \u001b[0m | \u001b[0m 764.7   \u001b[0m | \u001b[0m 238.3   \u001b[0m | \u001b[0m-9.209   \u001b[0m | \u001b[0m 3.506   \u001b[0m | \u001b[0m 0.01568 \u001b[0m |\n",
            "| \u001b[0m 41      \u001b[0m | \u001b[0m 0.1217  \u001b[0m | \u001b[0m 138.7   \u001b[0m | \u001b[0m 525.6   \u001b[0m | \u001b[0m 720.9   \u001b[0m | \u001b[0m-1.835   \u001b[0m | \u001b[0m 3.224   \u001b[0m | \u001b[0m 0.02666 \u001b[0m |\n",
            "| \u001b[0m 42      \u001b[0m | \u001b[0m 0.1533  \u001b[0m | \u001b[0m 414.5   \u001b[0m | \u001b[0m 403.5   \u001b[0m | \u001b[0m 762.9   \u001b[0m | \u001b[0m-1.136   \u001b[0m | \u001b[0m 1.77    \u001b[0m | \u001b[0m 0.02892 \u001b[0m |\n",
            "| \u001b[0m 43      \u001b[0m | \u001b[0m 0.1433  \u001b[0m | \u001b[0m 369.6   \u001b[0m | \u001b[0m 143.7   \u001b[0m | \u001b[0m 834.0   \u001b[0m | \u001b[0m-3.366   \u001b[0m | \u001b[0m 4.962   \u001b[0m | \u001b[0m 0.04218 \u001b[0m |\n",
            "| \u001b[0m 44      \u001b[0m | \u001b[0m 0.1217  \u001b[0m | \u001b[0m 384.4   \u001b[0m | \u001b[0m 761.0   \u001b[0m | \u001b[0m 660.2   \u001b[0m | \u001b[0m-4.242   \u001b[0m | \u001b[0m 5.461   \u001b[0m | \u001b[0m 0.0417  \u001b[0m |\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/bayes_opt/target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: (114.96039485732337, 680.7703941104195, 190.08744764805513, -2.606077461255431, 0.7003455017648615, 0.0017123174847413825)",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-245a7199abf0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m optimizer.maximize(\n\u001b[1;32m     32\u001b[0m     \u001b[0minit_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m )\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[0;34m(self, init_points, n_iter, acq, kappa, kappa_decay, kappa_decay_delay, xi, **gp_params)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0miteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_probe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlazy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bounds_transformer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mprobe\u001b[0;34m(self, params, lazy)\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOPTIMIZATION_STEP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/bayes_opt/target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-d3396a566bc9>\u001b[0m in \u001b[0;36mbayesian_optimization_function\u001b[0;34m(dataset_path, device, num_runs, batch_size, num_epochs, lr_power, weight_decay, num_layers, hidden_size, linear_size, verbose)\u001b[0m\n\u001b[1;32m     41\u001b[0m     mean_accuracy = test_hyper_parameters(num_runs=num_runs, dataset_path=dataset_path, batch_size=batch_size,\n\u001b[1;32m     42\u001b[0m                                           \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                                           model_cls=Model, model_args=model_args, device=device, verbose=verbose)\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'\\nMean accuracy: {mean_accuracy*100:.4f}%'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/emotion_from_speech/training.py\u001b[0m in \u001b[0;36mtest_hyper_parameters\u001b[0;34m(num_runs, dataset_path, batch_size, num_epochs, learning_rate, weight_decay, model_cls, model_args, device, verbose)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0maccuracies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mrun\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_runs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m         \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-d3396a566bc9>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, num_layers, feature_num, hidden_size, linear_size, classes)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         self.lstm = torch.nn.LSTM(num_layers=num_layers, input_size=feature_num, hidden_size=hidden_size,\n\u001b[0;32m---> 11\u001b[0;31m                                   batch_first=True)\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinear_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'LSTM'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, mode, input_size, hidden_size, num_layers, bias, batch_first, dropout, bidirectional)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mwn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mwn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_weights_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mflatten_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;31m# or the tensors in _flat_weights are of different dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mfirst_fw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfirst_fw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_weights\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GoTHCznmU5i",
        "outputId": "a202edfd-0814-4dc6-9fe4-b13c11d850ec"
      },
      "source": [
        "from functools import partial\r\n",
        "\r\n",
        "dataset_path = os.path.join(DATA_PATH, 'data_list.npy')\r\n",
        "\r\n",
        "fn = partial(bayesian_optimization_function, \r\n",
        "             dataset_path=dataset_path, device=device, \r\n",
        "             num_runs=1, num_epochs=30, \r\n",
        "             verbose=1)\r\n",
        "fn(\r\n",
        "batch_size = 220, \r\n",
        "    lr_power = -3.176741885237907,\r\n",
        "    weight_decay = 0.01608787733295929,\r\n",
        "    num_layers = 1.5341413530239114,\r\n",
        "    hidden_size = 813,\r\n",
        "    linear_size = 488,)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0:  Train Accuracy: 14.9000%\n",
            "Epoch 0:  Validation Accuracy: 18.0000%\n",
            "\n",
            "Epoch 1:  Train Accuracy: 17.7000%\n",
            "Epoch 1:  Validation Accuracy: 19.5000%\n",
            "\n",
            "Epoch 2:  Train Accuracy: 18.8500%\n",
            "Epoch 2:  Validation Accuracy: 21.5000%\n",
            "\n",
            "Epoch 3:  Train Accuracy: 21.2000%\n",
            "Epoch 3:  Validation Accuracy: 23.0000%\n",
            "\n",
            "Epoch 4:  Train Accuracy: 23.5000%\n",
            "Epoch 4:  Validation Accuracy: 27.5000%\n",
            "\n",
            "Epoch 5:  Train Accuracy: 25.2000%\n",
            "Epoch 5:  Validation Accuracy: 26.5000%\n",
            "\n",
            "Epoch 6:  Train Accuracy: 29.7000%\n",
            "Epoch 6:  Validation Accuracy: 23.5000%\n",
            "\n",
            "Epoch 7:  Train Accuracy: 33.2000%\n",
            "Epoch 7:  Validation Accuracy: 32.0000%\n",
            "\n",
            "Epoch 8:  Train Accuracy: 30.7000%\n",
            "Epoch 8:  Validation Accuracy: 29.0000%\n",
            "\n",
            "Epoch 9:  Train Accuracy: 34.0000%\n",
            "Epoch 9:  Validation Accuracy: 40.5000%\n",
            "\n",
            "Epoch 10:  Train Accuracy: 40.2000%\n",
            "Epoch 10:  Validation Accuracy: 40.0000%\n",
            "\n",
            "Epoch 11:  Train Accuracy: 40.2000%\n",
            "Epoch 11:  Validation Accuracy: 44.5000%\n",
            "\n",
            "Epoch 12:  Train Accuracy: 40.5000%\n",
            "Epoch 12:  Validation Accuracy: 41.0000%\n",
            "\n",
            "Epoch 13:  Train Accuracy: 42.8000%\n",
            "Epoch 13:  Validation Accuracy: 41.5000%\n",
            "\n",
            "Epoch 14:  Train Accuracy: 41.1500%\n",
            "Epoch 14:  Validation Accuracy: 46.0000%\n",
            "\n",
            "Epoch 15:  Train Accuracy: 46.9000%\n",
            "Epoch 15:  Validation Accuracy: 51.0000%\n",
            "\n",
            "Epoch 16:  Train Accuracy: 52.7000%\n",
            "Epoch 16:  Validation Accuracy: 39.5000%\n",
            "\n",
            "Epoch 17:  Train Accuracy: 52.1000%\n",
            "Epoch 17:  Validation Accuracy: 50.5000%\n",
            "\n",
            "Epoch 18:  Train Accuracy: 51.6500%\n",
            "Epoch 18:  Validation Accuracy: 50.0000%\n",
            "\n",
            "Epoch 19:  Train Accuracy: 52.7000%\n",
            "Epoch 19:  Validation Accuracy: 50.0000%\n",
            "\n",
            "Epoch 20:  Train Accuracy: 55.6000%\n",
            "Epoch 20:  Validation Accuracy: 50.5000%\n",
            "\n",
            "Epoch 21:  Train Accuracy: 55.5500%\n",
            "Epoch 21:  Validation Accuracy: 52.5000%\n",
            "\n",
            "Epoch 22:  Train Accuracy: 58.5500%\n",
            "Epoch 22:  Validation Accuracy: 53.0000%\n",
            "\n",
            "Epoch 23:  Train Accuracy: 56.5500%\n",
            "Epoch 23:  Validation Accuracy: 52.0000%\n",
            "\n",
            "Epoch 24:  Train Accuracy: 57.5500%\n",
            "Epoch 24:  Validation Accuracy: 52.5000%\n",
            "\n",
            "Epoch 25:  Train Accuracy: 53.7000%\n",
            "Epoch 25:  Validation Accuracy: 52.5000%\n",
            "\n",
            "Epoch 26:  Train Accuracy: 55.5500%\n",
            "Epoch 26:  Validation Accuracy: 53.5000%\n",
            "\n",
            "Epoch 27:  Train Accuracy: 59.6500%\n",
            "Epoch 27:  Validation Accuracy: 55.5000%\n",
            "\n",
            "Epoch 28:  Train Accuracy: 60.7500%\n",
            "Epoch 28:  Validation Accuracy: 57.0000%\n",
            "\n",
            "Epoch 29:  Train Accuracy: 63.4000%\n",
            "Epoch 29:  Validation Accuracy: 61.5000%\n",
            "\n",
            "Test Accuracy: 57.5000%\n",
            "\n",
            "Mean accuracy: 57.5000%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.575"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    }
  ]
}